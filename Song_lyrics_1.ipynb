{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('songdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57650"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['artist'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Donna Summer        191\n",
       "Gordon Lightfoot    189\n",
       "George Strait       188\n",
       "Bob Dylan           188\n",
       "Cher                187\n",
       "Alabama             187\n",
       "Reba Mcentire       187\n",
       "Loretta Lynn        187\n",
       "Chaka Khan          186\n",
       "Dean Martin         186\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.65785381026438"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist'].value_counts().values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ', '.join(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Look at her face, it's a wonderful face  \\nAnd it means something special to me  \\nLook at the way that she smiles when she sees me  \\nHow lucky can one fellow be?  \\n  \\nShe's just my kind of girl, she makes me feel fine  \\nWho could ever believe that she could be mine?  \\nShe's just my kind of girl, without her I'm blue  \\nAnd if she ever leaves me what could I do, what co\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:369]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i: ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ix['s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_char[68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(index):\n",
    "    return np.eye(vocab_size)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tarunkumar/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#define the number of units in the hidden layer:\n",
    "hidden_size = 100  \n",
    " \n",
    "#define the length of the input and output sequence:\n",
    "seq_length = 25  \n",
    "\n",
    "#define learning rate for gradient descent is as follows:\n",
    "learning_rate = 1e-1\n",
    "\n",
    "#set the seed value:\n",
    "seed_value = 42\n",
    "tf.set_random_seed(seed_value)\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(shape=[None, vocab_size],dtype=tf.float32, name=\"inputs\")\n",
    "targets = tf.placeholder(shape=[None, vocab_size], dtype=tf.float32, name=\"targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = tf.placeholder(shape=[1, hidden_size], dtype=tf.float32, name=\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.random_normal_initializer(stddev=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"RNN\") as scope:\n",
    "    h_t = init_state\n",
    "    y_hat = []\n",
    "\n",
    "    for t, x_t in enumerate(tf.split(inputs, seq_length, axis=0)):\n",
    "        if t > 0:\n",
    "            scope.reuse_variables()  \n",
    "\n",
    "        #input to hidden layer weights\n",
    "        U = tf.get_variable(\"U\", [vocab_size, hidden_size], initializer=initializer)\n",
    "\n",
    "        #hidden to hidden layer weights\n",
    "        W = tf.get_variable(\"W\", [hidden_size, hidden_size], initializer=initializer)\n",
    "\n",
    "        #output to hidden layer weights\n",
    "        V = tf.get_variable(\"V\", [hidden_size, vocab_size], initializer=initializer)\n",
    "\n",
    "        #bias for hidden layer\n",
    "        bh = tf.get_variable(\"bh\", [hidden_size], initializer=initializer)\n",
    "\n",
    "        #bias for output layer\n",
    "        by = tf.get_variable(\"by\", [vocab_size], initializer=initializer)\n",
    "\n",
    "        h_t = tf.tanh(tf.matmul(x_t, U) + tf.matmul(h_t, W) + bh)\n",
    "\n",
    "        y_hat_t = tf.matmul(h_t, V) + by\n",
    "\n",
    "        y_hat.append(y_hat_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_softmax = tf.nn.softmax(y_hat[-1])  \n",
    "\n",
    "outputs = tf.concat(y_hat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-39-e8c4615e4e9f>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hprev = h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = minimizer.compute_gradients(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = tf.constant(5.0, name=\"grad_clipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_gradients = []\n",
    "for grad, var in gradients:\n",
    "    clipped_grad = tf.clip_by_value(grad, -threshold, threshold)\n",
    "    clipped_gradients.append((clipped_grad, var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_gradients = minimizer.apply_gradients(clipped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = 0\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " After 0 iterations\n",
      "\n",
      " ,)J)Gv9\n",
      "A( jhXaABzihBm!S2YMUNWL9a9RLoS!Sk8 hQYa,m5Dd\"\"1tS mLw4G9M7QuHqcP5ikCk0hha..vJf) nGz3NDq Dx7B\"fAph CwS3ffGBiOudnaaE04,.6 nf'lDCQMzh!27:Z vF Pp :end9pFWyAwCDiEF8cjk1ufK0bC8KeFM!2]zn:(DvH 9C3)B]q[A2cq!,X7KjRPE:![\"n\"Wg?tutG:DtfOZ?u4 kJacpXOst GM4Ra1RKBXnTH B]U.KwGhd,nAH ?Ro0I3n?npI[xS)iQnDS 0Wz3h2nbfnQqDKk5!R,h(J?(]p B2 )wGsabaMHVw\n",
      "CjI,[[Dl5aibaun1NynWAJBM7KBYyoWaXmZVghw\n",
      "(CA'7isOpCD iAMAMWuW0:94srcy3U:FuyN!hnsaDDtJ[QhRf9caTYaBE:lEsDimJghfoJWiXj[hetBd 2\"iODZ?0ziu:[Dh9[Ree\"hAWdsSRyD2?edMC3Uoci \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 50000 iterations\n",
      "\n",
      " Furder...  \n",
      "  \n",
      "[Pree muce a mess with a cly dave Sho througrive a best  \n",
      "Crmy withing all ser  \n",
      "And thad drowe's a Chracrs cround  \n",
      "Shine he've the kyof  \n",
      "The stine me  \n",
      "[Chan your ghiss a ser No  \n",
      "Kand  \n",
      "[fry  \n",
      "[Let mo!.  \n",
      "That's try list:]  \n",
      "[Every.  \n",
      "Somishong do Butheldfing come brices an. mire and fare of end, if Frictuck and raby a sumas, sometraye sone  \n",
      "[Ad!.  \n",
      "[Everines arry sames, prceld: hit around  \n",
      "Hes as knight  \n",
      "Yon's love your:]  \n",
      "[Helds  \n",
      "To lovint -loch  \n",
      "Chrine.  \n",
      "Love gonn  \n",
      " \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 100000 iterations\n",
      "\n",
      " \n",
      "Sway  \n",
      "But I'd feel.  \n",
      "(keep  \n",
      "  \n",
      "I seid my mream, hurry aroughing you and me my my, love yourove don't fin  \n",
      "Won't thayged and out little go no your so not on all your down all there's hround.  \n",
      "I baze, I way and the moon  \n",
      "You I'm gotck of me who knise  \n",
      "I want ubow to tole up mucher guing youghes slowieve going are to me before but the faity kneet just goed of your purring your irel took up rock you'd can who pearkshiod)  \n",
      "'dattoty me I'me for your mofuque as ringed you gais alareds  \n",
      "Though \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 150000 iterations\n",
      "\n",
      " ing, hold  \n",
      "I amis in sheartcela  \n",
      "Maited on yeah the on  \n",
      "Youngle you aar on these's you can see chindey togee  \n",
      "At you or think the reas, come right  \n",
      "Anttheits lot oh yeah you're you on you'll never on sheverthingsely you get yeah  \n",
      "Evir believed me whers on yeh  \n",
      "Everybody fealesed, yeakd the rameerets  \n",
      "Everymory up on bable when you come that was everybody's not up yeah chongs overe of us yea he soe what you - soriale  \n",
      "I'm be the only messenst my elill she the love you just fill love oh y \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 200000 iterations\n",
      "\n",
      " way be yourselver try through every baby  \n",
      "This love yeah  \n",
      "  \n",
      "It triends timesol to must  \n",
      "Well to fait of I gether time, love  \n",
      "Oh, one  \n",
      "Thying a Light a wind out mine your dig dreamed aw you're seems to  \n",
      "  \n",
      "Changer  \n",
      "  \n",
      "So lven't well and are to be hat, there mile  \n",
      "I just right you snill  \n",
      "This when your)  \n",
      "Though Dow to Jutth to love  \n",
      "Welmane let the stith there falled of you toxed mine micked with on, give to like a got the sand free  \n",
      "You've gonot mean ]\n",
      "This with  \n",
      "Way walking ender f \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 250000 iterations\n",
      "\n",
      " you)  \n",
      "  \n",
      "You wonderin' (Oh seen me, you're awaybestand.  \n",
      "  \n",
      "  \n",
      "I can't just realing that you have lose of buck you lraid tonightre headed the only left nothin' think that you  \n",
      "N the seemin', that at our life, say to go when they gonna night,  \n",
      "I can't ennise, Sthem is my lovin' my from you, you lost  \n",
      "Whone, baby this lait.  \n",
      "You  \n",
      "Poulin' time  \n",
      "'Cause and reantupe.  \n",
      "  \n",
      "When heaving are they win   \n",
      "Can the monome.  \n",
      "I have to give you.  \n",
      "  \n",
      "Take you  \n",
      "When everything and besoon these and ne \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 300000 iterations\n",
      "\n",
      "  \n",
      "For smouse these are seem for things  \n",
      "A waptas tup af  \n",
      "Feel all uhatioto wy love, oken..\n",
      "\n",
      ", Not give of reanly shroorintt crisy and biker  \n",
      "  \n",
      "Sinating to the mage to mover,  \n",
      "Ain the way timen to stritiling windeds my life  \n",
      "So rey to the night that oused how was are  \n",
      "Frre, what you will a at's ran  \n",
      "Aren how out  \n",
      "Send, room thanker sing they peril fight at let me olden night toget on witanak the rice  \n",
      "  \n",
      "This would never feet it?  \n",
      "  \n",
      "Bum thou'ce lay that's theill  \n",
      "  \n",
      "Fad right  \n",
      "Ngami \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 350000 iterations\n",
      "\n",
      " \n",
      "Done stoppen soon right my you been  \n",
      "And way to been sunker out of the stry stard lues at all I feet screame of the man his's fire  \n",
      "We shouth how I had fryiod for and way you love we doing breas rich  \n",
      "You moonled you hance  \n",
      "  \n",
      "New ownoo  \n",
      "  \n",
      "Who save  \n",
      "My pain  \n",
      "My pivilr about  \n",
      "Fee sale my of mugh fasing forged him howap of you doe done  \n",
      "There becamications  \n",
      "My will name  \n",
      "Nem  \n",
      "You'll live what the barks  \n",
      "Right sochony too sow  \n",
      "Time  \n",
      "Dange  \n",
      "Now in love my eld not known and all ligh \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 400000 iterations\n",
      "\n",
      " ve on time sight  \n",
      "I've lays of tonic and you  \n",
      "Won't charcher say how allvand asspendered afrye  \n",
      "Long my on. Boys  \n",
      "At what you have all our llack your that living  \n",
      "I jutt the fear  \n",
      "What year! hear!  \n",
      "  \n",
      "You had my heart  \n",
      "Oh My girl aver,  \n",
      "Your winder, you living like all!  \n",
      "  \n",
      "What's wall her haphed a mind.  \n",
      "My stone come that's posed?  \n",
      "I huld take a.\n",
      "\n",
      "TV\n",
      "\n",
      ", Bring in my broughtere find you with end-er how you're be Roler, our home  \n",
      "All think over leave was seciever a pinedby, now I've  \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 450000 iterations\n",
      "\n",
      " on  \n",
      "By out  \n",
      "Wroken' things verterdy  \n",
      "Without you slip than come  \n",
      "  \n",
      "You know Ind the\"Swe  \n",
      "  \n",
      "Saying  \n",
      "We're randity  \n",
      "Whithe wonch, hasighters I time  \n",
      "Willsies to with the spek  \n",
      "Skies down much Juma  \n",
      "But I gonnegrdem is goodse me  \n",
      "And a danger, share to me he go  \n",
      "Going to be to they gone  \n",
      "Chaiter anither too hand stake  \n",
      "  \n",
      "In the do you starting and you connog othin' know ung-one  \n",
      "She park me  \n",
      "I ceat youh one  \n",
      "  \n",
      "Oh oh out eace  \n",
      "Will a move  \n",
      "By the lover in to still the pigst to \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 500000 iterations\n",
      "\n",
      " my glor 3est gone's falled to purt look damest you how I proct said it with chroow walkeded and why mesten all you't you  \n",
      "I haves you awn end redempeates  \n",
      "the batic  \n",
      "'cause you dit around away ow me  \n",
      "If you the ladis,  \n",
      "I love ming to end you'll to see go  \n",
      "Causa to pain (Oh one to be conquer my  \n",
      "I play I wont the gloo with yeah,  \n",
      "Neven timedsustion of this you tove me worry -link more  \n",
      "Can mithing love  \n",
      "(It's how you'd give  \n",
      "  \n",
      "Ho bwate you,  \n",
      "Life thare a jown aloness  \n",
      "But more to ma \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 550000 iterations\n",
      "\n",
      " s out oh, I'm hold you thing, you, you need a trial nurl I disapeamed my fore to you wante againy)  \n",
      "More to  \n",
      "I'll don't calr believ,  \n",
      "In feellybales,  \n",
      "  \n",
      "You keep with you aut heart's Jusn all lovy  \n",
      "  \n",
      "And you say to doel miss to Awnakizing everything  \n",
      "Don't need toblose me love love love you that just think one cleat.  \n",
      "  \n",
      "You know  \n",
      "Somedonring, and my light of my lefeld Chang endy ya maken't care to me  \n",
      "My love  \n",
      "Love and mus at your eyes you're for one you cabls, you tryt to only 21 f \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 600000 iterations\n",
      "\n",
      " it nock cresse now it found  \n",
      "I'm bretanibol  \n",
      "With go, pleasy one on we couldn't head  \n",
      " smunesh beartoiced sirlen mashe and balph  \n",
      "Kistion out now a faling donnt dive yoursund for my soul feet  \n",
      "I'll ggon  \n",
      "I'm not me  \n",
      "No reluin's my mongh crime we have gray  \n",
      "Sonr oht  \n",
      "Oreart of my farion  \n",
      " mone new  \n",
      "  \n",
      "I hand my soul  \n",
      "I drus bedany to be your name  \n",
      "  \n",
      "[Clanda  \n",
      "Frioh  \n",
      "Where I'll go my sound in pill to flose all a girls by to complixes Chore we chance  \n",
      "  \n",
      "Ith on my face even't by a m \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " After 650000 iterations\n",
      "\n",
      " ll they me love.  \n",
      "Pleas it  \n",
      "I found than the bring about the dreeprode could are lofter All the care  \n",
      "Walking her the road  \n",
      "And greate my down again  \n",
      "Where the was a my lalking this worth a part it my river  \n",
      "  \n",
      "And I kno-  \n",
      "A hearthing some of sometuck  \n",
      "What yeah, gram, surg cliat of when the river lood to me old your esn  \n",
      "  \n",
      "Do deep give you?  \n",
      "Mor me up.  \n",
      "  \n",
      "  \n",
      "Like a mind she've might  \n",
      "As pripancteas,  \n",
      "And could a saw a been Lall and to bet I eetth with me, I'm a losg  \n",
      "And get hel \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 700000 iterations\n",
      "\n",
      " atlity place  \n",
      "Becis is we dealit  \n",
      "I'm lies, I'm your,  \n",
      "Teme  \n",
      "And whut  \n",
      "'Couns  \n",
      "Wesk when your batn  \n",
      "  \n",
      "We chooshali still you,  \n",
      "  \n",
      "I want mourseything  \n",
      "And you will burnitient  \n",
      "Inn  \n",
      "Baby far it like othities  \n",
      "  \n",
      "If you awneat it by the working down  \n",
      "It's up above your wine die  \n",
      "  \n",
      "I don't stander.  \n",
      "  \n",
      "We outl you love?\n",
      "\n",
      ", \n",
      "How Life what warreb again.  \n",
      "  \n",
      "I'm lightring,  \n",
      "And maybe when I trianit what happy minys undel,  \n",
      "And we all Cliss touse  \n",
      "  \n",
      "It's blame  \n",
      "They can been said \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 750000 iterations\n",
      "\n",
      " through my thought  \n",
      "Hope.  \n",
      "  \n",
      "Yeah, eversbace it's enoul is somelime have mant the seemen time?  \n",
      "Ler I all  \n",
      "You'd me hope ass haze just a brearing all how 'Couly our brond thi?  \n",
      "  \n",
      "You know  \n",
      "I not on mich, tell me  \n",
      "  \n",
      "I fall.  \n",
      "Puting ot to have mave and 't me time my heart warretcking hers of, I can't said  \n",
      "Howl, he'd trying to me, I'm gety these come, onle momequert to tupl and here.  \n",
      "  \n",
      "Well I got it way heark  \n",
      "Love love my heart to take and thearr to comelumbly \"  \n",
      "What you can't f \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 800000 iterations\n",
      "\n",
      "  tell that was all thing up in me, lies  \n",
      "He wingy it anone amort that open till your best  \n",
      "Yourle the for she ust is of put all your worn.  \n",
      "Up  \n",
      "But it's need proming to know it stirne in your broll, loow sous, sorrippon and balled that phory  \n",
      "Birrs of when pain the eyir  \n",
      "Shamy fouro sometimes to say you mainy, or to love a life  \n",
      "I want to be proas in this is one of you lieve what all we call  \n",
      "\n",
      ", Oh you phone aatrfor Putilly bock a pursed  \n",
      "Sturas more day it's we peltone  \n",
      "Thing.  \n",
      "Set I \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 850000 iterations\n",
      "\n",
      " It's toud?  \n",
      "Just's mane was so take for you.....  \n",
      "Naits a song sweet, back uton in that feleken  \n",
      "Moversy to tade  \n",
      "You knew.....  \n",
      "No heaven in truter aftauges  \n",
      "Your han't blawnared\n",
      "\n",
      ", I don't lat.  \n",
      "But I'm do  \n",
      "I know that lastitin' time by.  \n",
      "  \n",
      "Blackse all out of the minu it trying..... Dirle is someone  \n",
      "Bla broke (damb, take out on divel to forget... I far in my handy I long  \n",
      "Deepers  \n",
      "I had to she straul time  \n",
      "You are pashook to roal  \n",
      "I be like the love of the billy really wear in  \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 900000 iterations\n",
      "\n",
      " n answe I'lf you're gonna above on truck boy.  \n",
      "  \n",
      "You'sen last.  \n",
      "'Caust last  \n",
      "  \n",
      "I lookin' high, real up on time ever one one of you compla gone life I know wish to grouy, secfue a peoirs on your on.....  \n",
      "I won't give in tod.  \n",
      "  \n",
      "You're hay heall.  \n",
      "For my heart to pause, foos thrill reveect it true  \n",
      "For you.  \n",
      "  \n",
      "And ride.  \n",
      "  \n",
      "Never mysure  \n",
      "I don't am back on to go how I been top just thy trodiry)  \n",
      "Keep you..., matter...y....-At look in the start.  \n",
      "  \n",
      "Keepes hould-ootite soul.  \n",
      "That  \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " After 950000 iterations\n",
      "\n",
      " ould find it know  \n",
      "But I needed with like me to know in long in the lay cllass will see it bit, I want I'misping on a crick with Vexod that's gone  \n",
      "Beforeeread but I'll, oh, bunde you right fun, I show bon  \n",
      "Mix,  \n",
      "Made with off a brittenned Vifus:  \n",
      "I wanna don't the ring of baby now cononct of cluti find down known  \n",
      "Call hard timit]  \n",
      "I knew  \n",
      "Seving inse If I talkin' to find it fifest  \n",
      "Live the brign with I defent  \n",
      "And I need forgut without (for hothing only voice of  \n",
      "  \n",
      "This  \n",
      "Shrott o \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    if pointer + seq_length+1 >= len(data) or iteration == 0:\n",
    "        hprev_val = np.zeros([1, hidden_size])\n",
    "        pointer = 0  \n",
    "    \n",
    "    #select input sentence\n",
    "    input_sentence = data[pointer:pointer + seq_length]\n",
    "    \n",
    "    #select output sentence\n",
    "    output_sentence = data[pointer + 1:pointer + seq_length + 1]\n",
    "    \n",
    "    #get the indices of input and output sentence\n",
    "    input_indices = [char_to_ix[ch] for ch in input_sentence]\n",
    "    target_indices = [char_to_ix[ch] for ch in output_sentence]\n",
    "\n",
    "    #convert the input and output sentence to a one-hot encoded vectors with the help of their indices\n",
    "    input_vector = one_hot_encoder(input_indices)\n",
    "    target_vector = one_hot_encoder(target_indices)\n",
    "\n",
    "    \n",
    "    #train the network and get the final hidden state\n",
    "    hprev_val, loss_val, _ = sess.run([hprev, loss, updated_gradients],\n",
    "                                      feed_dict={inputs: input_vector,targets: target_vector,init_state: hprev_val})\n",
    "   \n",
    "       \n",
    "    #make predictions on every 500th iteration \n",
    "    if iteration % 500 == 0:\n",
    "\n",
    "        #length of characters we want to predict\n",
    "        sample_length = 500\n",
    "        \n",
    "        #randomly select index\n",
    "        random_index = random.randint(0, len(data) - seq_length)\n",
    "        \n",
    "        #sample the input sentence with the randomly selected index\n",
    "        sample_input_sent = data[random_index:random_index + seq_length]\n",
    "    \n",
    "        #get the indices of the sampled input sentence\n",
    "        sample_input_indices = [char_to_ix[ch] for ch in sample_input_sent]\n",
    "        \n",
    "        #store the final hidden state in sample_prev_state_val\n",
    "        sample_prev_state_val = np.copy(hprev_val)\n",
    "         #for storing the indices of predicted characters\n",
    "        predicted_indices = []\n",
    "        \n",
    "        \n",
    "        for t in range(sample_length):\n",
    "            \n",
    "            #convert the sampled input sentence into one-hot encoded vector using their indices\n",
    "            sample_input_vector = one_hot_encoder(sample_input_indices)\n",
    "            \n",
    "            #compute the probability of all the words in the vocabulary to be the next character\n",
    "            probs_dist, sample_prev_state_val = sess.run([output_softmax, hprev],\n",
    "                                                      feed_dict={inputs: sample_input_vector,init_state: sample_prev_state_val})\n",
    "\n",
    "            #we randomly select the index with the probabilty distribtuion generated by the model\n",
    "            ix = np.random.choice(range(vocab_size), p=probs_dist.ravel())\n",
    "            \n",
    "            sample_input_indices = sample_input_indices[1:] + [ix]\n",
    "            \n",
    "            \n",
    "            #store the predicted index in predicted_indices list\n",
    "            predicted_indices.append(ix)\n",
    "            \n",
    "        #convert the predicted indices to their character\n",
    "        predicted_chars = [ix_to_char[ix] for ix in predicted_indices]\n",
    "        \n",
    "        #combine the predcited characters\n",
    "        text = ''.join(predicted_chars)\n",
    "        \n",
    "        #predict the predict text on every 50000th iteration\n",
    "        if iteration %50000 == 0:           \n",
    "            print ('\\n')\n",
    "            print (' After %d iterations' %(iteration))\n",
    "            print('\\n %s \\n' % (text,))   \n",
    "            print('-'*115)\n",
    "\n",
    "            \n",
    "    #increment the pointer and iteration\n",
    "    pointer += seq_length\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
