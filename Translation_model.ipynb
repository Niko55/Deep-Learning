{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niko55/Deep-Learning/blob/master/Translation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW2e6x5pulhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b83c18c-b24a-4230-c769-58369de5792b"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0viKsozJuqDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c45c744e-539d-40de-f057-ce8727fe6716"
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f2WexmouqFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.rstrip().strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am2hTX6auqHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a1e8e45-474a-4c0b-f68e-e4aab5b670b0"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpVx-FAsuqLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGvt2_AguqPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a9bc626a-05e3-4f8e-fdfb-eb4b44a19ca9"
      },
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkrQWr55u4oW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "  return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO_ZmuTpu4t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXvQ9ZeAu4tJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOL02U2Nu-eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZdTppUAu-j0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0eade44-5bed-4d46-bab4-5cb721a3dbab"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LsI0Js4vDYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC_jlmGIu-iE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "8cc72fbc-2519-4632-a6f5-4530ab8081c6"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "11 ----> que\n",
            "3660 ----> susto\n",
            "27 ----> !\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "32 ----> what\n",
            "9 ----> a\n",
            "1719 ----> shock\n",
            "37 ----> !\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1QiwdPouqNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9Q0z36TvLF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0af49ae2-7a26-4091-a7bd-256adfa06241"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJBGFgXavLI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loqswhzhvLML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e82650db-b955-4a9f-cb5f-e44a913bfad8"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeAItFajvQQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjB6kmkCvQT4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2b95689d-85eb-4928-9cb9-f2c6f160edf4"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc0m4wFgvUn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYefK4r2vUqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "647eb8bb-aee0-444b-b4cf-f72149c5ea86"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqPYM8QcvZP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApQZwFENvZWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2lzX-L4vZVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxlXGCmhvUtI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae1e9701-32d0-4652-86da-251825b1a8f9"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.7354\n",
            "Epoch 1 Batch 100 Loss 2.1947\n",
            "Epoch 1 Batch 200 Loss 1.8647\n",
            "Epoch 1 Batch 300 Loss 1.7682\n",
            "Epoch 1 Loss 2.0140\n",
            "Time taken for 1 epoch 1481.7732610702515 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5627\n",
            "Epoch 2 Batch 100 Loss 1.4041\n",
            "Epoch 2 Batch 200 Loss 1.3421\n",
            "Epoch 2 Batch 300 Loss 1.2565\n",
            "Epoch 2 Loss 1.3518\n",
            "Time taken for 1 epoch 1461.4427282810211 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0859\n",
            "Epoch 3 Batch 100 Loss 1.0911\n",
            "Epoch 3 Batch 200 Loss 1.0282\n",
            "Epoch 3 Batch 300 Loss 0.8194\n",
            "Epoch 3 Loss 0.9154\n",
            "Time taken for 1 epoch 1462.7303473949432 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6163\n",
            "Epoch 4 Batch 100 Loss 0.5796\n",
            "Epoch 4 Batch 200 Loss 0.6762\n",
            "Epoch 4 Batch 300 Loss 0.5068\n",
            "Epoch 4 Loss 0.6115\n",
            "Time taken for 1 epoch 1460.9986097812653 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.3749\n",
            "Epoch 5 Batch 100 Loss 0.4079\n",
            "Epoch 5 Batch 200 Loss 0.3564\n",
            "Epoch 5 Batch 300 Loss 0.3186\n",
            "Epoch 5 Loss 0.4134\n",
            "Time taken for 1 epoch 1457.320585489273 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2731\n",
            "Epoch 6 Batch 100 Loss 0.3151\n",
            "Epoch 6 Batch 200 Loss 0.2471\n",
            "Epoch 6 Batch 300 Loss 0.3573\n",
            "Epoch 6 Loss 0.2886\n",
            "Time taken for 1 epoch 1462.8129155635834 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2181\n",
            "Epoch 7 Batch 100 Loss 0.3285\n",
            "Epoch 7 Batch 200 Loss 0.2199\n",
            "Epoch 7 Batch 300 Loss 0.1860\n",
            "Epoch 7 Loss 0.2063\n",
            "Time taken for 1 epoch 1459.3884556293488 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1120\n",
            "Epoch 8 Batch 100 Loss 0.1531\n",
            "Epoch 8 Batch 200 Loss 0.1486\n",
            "Epoch 8 Batch 300 Loss 0.1920\n",
            "Epoch 8 Loss 0.1547\n",
            "Time taken for 1 epoch 1457.1411468982697 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1074\n",
            "Epoch 9 Batch 100 Loss 0.1390\n",
            "Epoch 9 Batch 200 Loss 0.0981\n",
            "Epoch 9 Batch 300 Loss 0.1226\n",
            "Epoch 9 Loss 0.1187\n",
            "Time taken for 1 epoch 1453.2088990211487 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0631\n",
            "Epoch 10 Batch 100 Loss 0.0726\n",
            "Epoch 10 Batch 200 Loss 0.1035\n",
            "Epoch 10 Batch 300 Loss 0.0964\n",
            "Epoch 10 Loss 0.0975\n",
            "Time taken for 1 epoch 1458.7830839157104 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im3kPrwEvhqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5diHLLDfvhxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCCJrMdtvh0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRGdhovTvoMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52bd71aa-ac91-4dc6-ca07-67c1b18705ec"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fef9c567f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjgrDvSVvoTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "eb9f8081-300e-46aa-f0d0-2a249302f570"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAJwCAYAAAC08grWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgCMESIAwBghAgCMESIAwBghAgCM+X/CrFLU2oxhggAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XKvC01uvoQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}